{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ALTON LAVIN D'SOUZA","text":""},{"location":"#introduction","title":"Introduction","text":"<p>My Name is Alton Lavin D'souza, I am currently a Master's student at the University of Alberta studying Electrical and Computer Engineering with a focus on Integrated Circuits &amp; Systems. Prior to </p>"},{"location":"projects/arrhythmia/","title":"Arrhythmia Detection","text":""},{"location":"projects/arrhythmia/#project-link","title":"Project Link","text":""},{"location":"projects/arrhythmia/#introduction","title":"Introduction","text":"<p>We will be using the MIT data to train a model to detect Arrhythmias.</p>"},{"location":"projects/arrhythmia/#summary-of-project","title":"Summary of Project","text":"<p>We are using the ECG data collected by BIH and MIT, to see the distribution of the data you can check the </p>"},{"location":"projects/arrhythmia/#summary-of-the-data-after-analyzing","title":"Summary of the data after analyzing.","text":"<ul> <li>No. of records: 48</li> <li>Frequency : 360 samples per second</li> <li>Distribution: 25 male subjects between the ages of 32 and 89, 22 female subjects aged from 23 to 89 years. 60% of the total subjects were inpatient.</li> </ul>"},{"location":"projects/arrhythmia/#aim","title":"Aim","text":"<p>We will focus on classification of 5 classes, namely:</p> <ol> <li>Normal (N)</li> <li>Paced Beat (/)</li> <li>Right Bundle Branch Block Beat (R).</li> <li>Left Bundle Branch Block (L).</li> <li>Premature Ventricular Beat (V)</li> </ol>"},{"location":"projects/arrhythmia/#type-of-problem","title":"Type of problem","text":"<ol> <li>Classification problem</li> <li>Supervised Learning problem.</li> </ol>"},{"location":"projects/arrhythmia/#tools-and-frameworks","title":"Tools And Frameworks","text":"<ul> <li>WFDB</li> <li>Pytorch</li> <li>Pandas</li> <li>Seaborn</li> <li>py-ecg-detector</li> <li>imbalanced-learn</li> </ul>"},{"location":"projects/arrhythmia/#steps-to-implement-in-code","title":"Steps to Implement in Code","text":"<ol> <li>Break each record into fragments by detecting the peaks and taking a window before and after the peak</li> <li>Tranform the peak into feature vectors such that the number of dimensions is less than the original</li> <li>Fit the data to a model</li> <li>Report metrics</li> </ol>"},{"location":"projects/arrhythmia/#approaches","title":"Approaches","text":""},{"location":"projects/arrhythmia/#dimensionality-reduction-techniques","title":"Dimensionality Reduction Techniques","text":"<p>There are many dimensionality reduction methods, but some of the most common include:</p> <ul> <li>Principal component analysis (PCA) is a linear dimensionality reduction method that projects data points onto a lower-dimensional subspace in such a way that the variance of the data in the new space is maximized. This means that PCA finds the directions in the data that have the most variation, and projects the data points onto those directions.</li> <li>Factor analysis (FA) is another linear dimensionality reduction method that is similar to PCA. However, FA is designed to find latent factors that explain the variation in the data. These factors are not necessarily orthogonal, as they can be correlated with each other.</li> <li>Linear discriminant analysis (LDA) is a linear dimensionality reduction method that is specifically designed for classification tasks. LDA projects data points onto a lower-dimensional subspace in such a way that the classes are as well-separated as possible.</li> <li>Non-negative matrix factorization (NMF) is a nonlinear dimensionality reduction method that is often used for text analysis. NMF decomposes a matrix into two matrices, where the rows of the first matrix represent the original data points and the columns of the second matrix represent the latent factors.</li> <li>Sparse coding is a nonlinear dimensionality reduction method that is often used for image analysis. Sparse coding decomposes an image into a set of basis images, where each basis image is weighted by a coefficient. The coefficients are typically sparse, meaning that most of them are zero.</li> </ul> <p>These are just a few of the many dimensionality reduction methods that are available. The best method to use for a particular task will depend on the nature of the data and the goals of the analysis.</p> <p>Here are some of the benefits of using dimensionality reduction methods:</p> <ul> <li>Reduced computational complexity: When you reduce the dimensionality of your data, you also reduce the computational complexity of tasks such as clustering, classification, and regression. This can be a major advantage when you are working with large datasets.</li> <li>Improved visualization: When you reduce the dimensionality of your data, you can often visualize it more easily. This can be helpful for understanding the relationships between different variables and for identifying patterns in the data.</li> <li>Improved performance: In some cases, dimensionality reduction can actually improve the performance of machine learning models. This is because dimensionality reduction can help to remove noise from the data and to make the data more regular.</li> </ul> <p>However, there are also some potential drawbacks to using dimensionality reduction methods:</p> <ul> <li>Loss of information: When you reduce the dimensionality of your data, you lose some of the information in the original data. This can be a problem if the information that is lost is important for the task that you are trying to perform.</li> <li>Data distortion: In some cases, dimensionality reduction can distort the data. This can make it more difficult to interpret the results of your analysis.</li> <li>Overfitting: If you reduce the dimensionality of your data too much, you can end up overfitting your model to the training data. This can lead to poor performance on the test data.</li> </ul> <p>Overall, dimensionality reduction can be a powerful tool for data analysis. However, it is important to be aware of the potential drawbacks of these methods before using them.</p>"},{"location":"projects/arrhythmia/#loss-function-techniques","title":"Loss Function Techniques","text":"<p>Here are some of the most common loss functions used in machine learning:</p> <ul> <li>Mean squared error (MSE): This is the most common loss function for regression problems. It measures the squared difference between the predicted values and the actual values.</li> <li>Mean absolute error (MAE): This is another common loss function for regression problems. It measures the absolute difference between the predicted values and the actual values.</li> <li>Cross-entropy loss: This is the most common loss function for classification problems. It measures the difference between the predicted probabilities and the actual labels.</li> <li>Hinge loss: This is a loss function that is often used for support vector machines. It measures the distance between the decision boundary and the data points.</li> <li>Huber loss: This is a loss function that is less sensitive to outliers than MSE. It is often used for regression problems where there may be outliers in the data.</li> <li>Logistic loss: This is a loss function that is often used for logistic regression. It measures the log-likelihood of the data given the model parameters.</li> </ul> <p>The best loss function to use for a particular problem will depend on the nature of the data and the goals of the model. For example, MSE is often a good choice for regression problems where the data is normally distributed. Cross-entropy loss is often a good choice for classification problems where the classes are well-separated.</p> <p>It is important to note that loss functions are not always used to train machine learning models. In some cases, they can be used to evaluate the performance of a model after it has been trained. For example, you might use MSE to evaluate the accuracy of a regression model.</p>"},{"location":"projects/arrhythmia/#hyperparameter-tuning-approaches","title":"Hyperparameter Tuning Approaches","text":"<ol> <li>Grid Search </li> <li>Random Search</li> <li>Bayesian Optimization</li> </ol>"},{"location":"projects/arrhythmia/#machine-learning-signal-pre-processing-techniques","title":"Machine learning signal pre-processing techniques","text":"<p>We will be using the following pre-processing techniques:</p> <ol> <li>Fast Fourier Transform</li> <li>Discrete Wavelet Transform</li> <li>Calculate Feature Vectors by Simpsons Rule. Deep learning will not require pre-processing since it is meant to learn features by itself, we will however experiment and see the results.</li> </ol>"},{"location":"projects/arrhythmia/#machine-learning-approaches","title":"Machine Learning Approaches","text":"<p>We will be surveying the following algorithms in the is project:</p> <ol> <li>Logistic Regression</li> <li>Naive Bayes</li> <li>K-Nearest Neighbors</li> <li>Decision Tree</li> <li>Support Vector Machines</li> <li>Random Forest</li> </ol>"},{"location":"projects/arrhythmia/#deep-learning-approaches","title":"Deep Learning Approaches","text":"<p>We will be leveragin Supervised learning tasks:</p> <p></p> <p>We will be using CNNs for images primarily</p>"},{"location":"projects/arrhythmia/#goals-and-milestones","title":"Goals and Milestones","text":"<ul> <li>[x] Download the data</li> <li>[x] Summarise understanding of the data like the distribution and probabilites and other statical information</li> <li>[x] Pre-process the data</li> <li>[x] Train the data to create a machine learning model</li> <li>[x] Test the machine learning model with unseen data</li> <li>[x] Train the data to creat a deep learning model</li> <li>[x] Test the deep learning model with unseen data</li> <li>[x] Containerise Model for use with streamlit for easy future testing.</li> </ul>"},{"location":"projects/arrhythmia/#questions","title":"Questions","text":"Question Answers What is suppose to be the buffer size of the signal that we take? 200 How many classes do we consider? Refer this Do we always extract the QRS complex? Yes What are we looking for in an ECG Data? Leverage AI to extract features Do we Normalize or standardise the data the data? Yes"},{"location":"projects/arrhythmia/#resources","title":"Resources","text":"<ul> <li>https://realpython.com/python-scipy-fft/</li> <li>https://swharden.com/blog/2020-09-23-signal-filtering-in-python/</li> <li>https://danielmuellerkomorowska.com/2020/06/02/smoothing-data-by-rolling-average-with-numpy/</li> <li>https://refactored.ai/microcourse/notebook?path=content%2F06-Classification_models_in_Machine_Learning%2F02-Multivariate_Logistic_Regression%2Fmulticlass_logistic-regression.ipynb</li> <li>https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/</li> <li>https://towardsdatascience.com/how-to-convert-jupyter-notebooks-into-pdf-5accaef3758</li> </ul>"},{"location":"projects/arrhythmia/#processed-data","title":"Processed Data","text":"<p>https://drive.google.com/file/d/1ANq9kiWBsPsQpmsfJ-v4fpOMn0lEKypv/view?usp=sharing</p>"},{"location":"projects/arrhythmia/#useful-commands","title":"Useful commands","text":""},{"location":"projects/arrhythmia/#to-convert-notebooks-to-pdf","title":"To convert notebooks to PDF","text":"<pre><code> jupyter nbconvert --to pdf Machine\\ Learning.ipynb\n</code></pre>"},{"location":"projects/chest_x_rays/","title":"Corona Virus Detection in Chest X-Rays","text":""},{"location":"projects/chest_x_rays/#overview","title":"Overview","text":"<p>This project is an attempt to develop a system that can classify lung X-ray images with an  emphasis to detect X-ray images with COVID-19. In this project we will make use of image  processing techniques learned in class and implement a classification system that can sort out  the COVID-19 X-rays from the X-rays that are normal and have Pneumonia. This project will  include image collection, image processing and image classification with the help of Deep neural  networks namely CNN. As an aside we will also explore the performance of a machine learning  model especially KNN. This project should yield a robust classifier that can help detect COVID19 in a given image</p>"},{"location":"projects/chest_x_rays/#introduction","title":"Introduction","text":"<p>The new decade of the 21st century (2020) started with the emergence of a novel  coronavirus known as SARS-CoV-2 that caused an epidemic of coronavirus disease (COVID-19)  in Wuhan, China. It is the third highly pathogenic and transmissible coronavirus after severe acute  respiratory syndrome coronavirus (SARS-CoV) and Middle East respiratory syndrome  coronavirus (MERS-CoV) emerged in humans. [6] The virus, primarily affecting the respiratory  system, prompted a dire need for rapid and accurate diagnostic tools. Owing to the development of molecular biology technologies, molecular diagnostic  methods have developed rapidly. Among these, polymerase chain reaction (PCR)-based assays  are regarded as the gold standard for virus detection because of their high sensitivity and  specificity.[7] However, the test is too difficult to be widely used and it requires expensive  laboratory equipment and highly-trained laboratory staff. Additionally, it faces limitations in  sensitivity, impacting its effectiveness in certain scenarios.[8] X-ray imaging emerged as a crucial diagnostic method due to its ability to reveal distinct  lung patterns associated with COVID-19. Leveraging this characteristic, our project aims to  employ advanced deep learning and machine learning models to detect COVID-19 from X-ray  images. The researchers are trying to inculcate artificial intelligence (Machine learning or deep  2 learning models) for the efficient detection of COVID-19.[9] By amalgamating diverse datasets  encompassing COVID-19 X-ray images alongside normal and pneumonia-afflicted chest X-rays,  we seek to develop an automated classification system. This study compares the efficacy of deep learning, particularly Convolutional Neural  Networks (CNNs), with machine learning methodologies in identifying COVID-19 patterns within  X-ray images. The overarching goal is to contribute to the development of an intelligent diagnostic  tool that aids healthcare professionals in swift and accurate COVID-19 diagnoses based on X-ray  imagery.</p>"},{"location":"projects/chest_x_rays/#background-information","title":"Background Information","text":""},{"location":"projects/chest_x_rays/#what-is-covid-19","title":"What is COVID-19?","text":"<p>This is a virus which has been circulating the globe since 2019 . This virus is accompanied  by symptoms like dry cough, fever, shortness of breath and a loss of smell and taste.This was  considered as a respiratory virus. It is reported that most cases of this disease are mild and after  running the full course of the virus most patients recover. However, the severe course of this  disease is pneumonia-like and may result in death. In some cases also we see symptoms like  headaches, aching limbs, sore throat and sniffles. As a consequence of this disease, patients  have experienced damages to their nerves and cardiovascular system. [1,2</p>"},{"location":"projects/chest_x_rays/#use-of-x-rays-as-an-alternative-to-testing-kit","title":"Use of X Rays as an alternative to testing kit","text":"<p>When COVID-19 when was rampant, there was an increase in COVID-19 patients which  strained the healthcare systems around the world. At the time when COVID-10 was at its peak,  there were limited kits for diagnosis but also limited hospital beds, personal protective equipment  and ventilators. Due to the sheer volume of the patients, it becomes increasingly important to  distinguish patients with severe acute respiratory illness(SARI) and COVID-19.Soon the world  found itself using X-rays and devising tools with the help of it to classify X-rays. X-rays are not  only cheap but are commonly found in various diagnostic settings. Also, they are well integrated  into the digital infrastructure. Lastly, portable X-rays also allow for the creation of makeshift  isolation wards reducing the need of PPE kits[2].</p>"},{"location":"projects/chest_x_rays/#related-works","title":"Related Works","text":"<p>This idea is not a novel idea and there are many models and works surrounding X-rays.  Most of these use machine learning and deep learning techniques coupled with image processing  techniques that will help classify X-Ray images. The need for such systems was spurred on by  the lack of healthcare professionals to interpret the results. However, such systems are to be  used for triaging purposes [2].   Some works are:   Coronet[4], which is a Deep Convolutional Neural Network model that automatically  detects COVID-19 infection from chest X-ray images. The model the authors proposed is based  on Xception architectures with its weights pre trained on ImageNet. Transfer learning is then done  on the COVID-19 data set and pneumonia datasets which are publicly available. This model has  achieved an overall accuracy of 89.6%. The model was experimented with 4 class classification  scenarios(COVID,Pneumonia bacterial,Pneumonia viral,normal) and 3 class  classification(COVID,Pneumonia,normal). The model achieved an overall accuracy of 89.6% and  95% respectively.   \"Automated detection of COVID-19 cases using deep neural networks with X-ray  images''[5], makes use of deep neural networks. However, the model so developed here was  experimented for 2 class classification(COVID, No Findings) and 3 class classification(COVID,  No findings, Pneumonia). The paper has implemented a DarkNet model that uses a you only look  once real time object detection system and has achieved an accuracy of 98% for binary  classification and 87% for multiclass classification.   COVID-NET[6], it's the first open source network design for chest X-ray Images. In  addition to this the study creates a database for COVID-19 against which we can benchmark our  models and saves the trouble for creating the dataset. Transfer Learning approach was  undertaken here where the COVID-NET model was first pre trained on Imagenet and then on the  COVIDx dataset. 3 classes was used for classification and a comparison was done against other  pretrained models like ResNET-50 and VGG-19 and COVID-NET was found to perform better  than these models. The number of parameters and mathematical operations used in COVID-NET  was less compared to ResNET-50 and VGG-19.</p>"},{"location":"projects/chest_x_rays/#implemented-method","title":"Implemented Method","text":"<p>In our project we will have the following tasks:</p>"},{"location":"projects/chest_x_rays/#data-collection","title":"Data Collection","text":"<p>For our project we will be collecting data from 2 data sources: 1. Covid 19 X-Ray DataSet [11] 2. Bacterial and Viral Pneumonia</p>"},{"location":"projects/chest_x_rays/#covid-19-x-ray-dataset","title":"Covid 19 X-Ray DataSet","text":"<p>This data has the following distribution illustrated in the following image:</p> <p></p> <p>From this data set we take images that are labeled as COVID and the X-ray image is in the  anteroposterior (AP) or in the anteroposterior supine position(AP Supine).</p> <p>The COVID images were stored in the following formats:</p>"}]}