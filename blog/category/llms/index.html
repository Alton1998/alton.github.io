
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://Alton1998.github.io/alton.github.io/blog/category/llms/">
      
      
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>LLMs - Alton Lavin D'Souza</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
    <meta name="google-site-verification" content="oXpHIsgH9DHTXwNuaKltPOEu7XdN7F5dS9DmfEjCWNo" />

  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Alton Lavin D&#39;Souza" class="md-header__button md-logo" aria-label="Alton Lavin D'Souza" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Alton Lavin D'Souza
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              LLMs
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Alton Lavin D&#39;Souza" class="md-nav__button md-logo" aria-label="Alton Lavin D'Souza" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Alton Lavin D'Souza
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Work Experience
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Work Experience
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../work_experience/oracle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Oracle
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Projects
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Projects
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../projects/arrhythmia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Arrhythmia Detection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../projects/chest_x_rays/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Corona Virus Detection in Chest X-Rays
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../projects/tpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tensor Processing Unit
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Blog
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content" data-md-component="content">
    <div class="md-content__inner">
      <header class="md-typeset">
        <h1 id="llms">LLMs</h1>
      </header>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/39479720?s=400&u=17af60674de436a0ef97d3e528947194708b03bd&v=4" alt="Alton Lavin D'souza">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2025-01-09 00:00:00+00:00">January 9, 2025</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="../artificial-neural-networks/" class="md-meta__link">Artificial Neural Networks</a>, 
              <a href="../artificial-intelligence/" class="md-meta__link">Artificial Intelligence</a>, 
              <a href="./" class="md-meta__link">LLMs</a>, 
              <a href="../vlms/" class="md-meta__link">VLMs</a>, 
              <a href="../llava/" class="md-meta__link">LLaVA</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="llava"><a class="toclink" href="../../2025/01/09/llava/">LLaVA</a></h2>
<h3 id="overview"><a class="toclink" href="../../2025/01/09/llava/#overview">Overview</a></h3>
<p>LLaVA (Large Language and Vision Assistant) was first introduced in the paper "Visual Instruction Tuning".</p>
<h3 id="what-is-visual-instruction-tuning"><a class="toclink" href="../../2025/01/09/llava/#what-is-visual-instruction-tuning">What is Visual Instruction Tuning?</a></h3>
<p>Visual instruction tuning is a method used to fine-tune a large language model, enabling it to interpret and respond to instructions derived from visual inputs.</p>
<p>One example is to ask a machine learning model to describe an image.</p>
<h3 id="llava_1"><a class="toclink" href="../../2025/01/09/llava/#llava_1">LLaVA</a></h3>
<p>As already established LLaVA is a multimodal model. LLaVA was trained on a small dataset. Despite this it can perform image analysis and respond to questions.</p>
<h4 id="architecture"><a class="toclink" href="../../2025/01/09/llava/#architecture">Architecture</a></h4>
<p>The LLaVA has the following components:
1. Language model
2. Vision Encoder
3. Projection</p>
<p>We use the Llama as the language model, which is a family of autoregressive LLMs released by Meta AI.</p>
<p>The vision encoder is implemented by CLIP visual encoder ViT-L/14. The encoder extracts visual features and connects them to language embeddings through a projection matrix. The projection component translates visual features into language embedding tokens, thereby bridgin the gap between text and images.</p>
<h4 id="training"><a class="toclink" href="../../2025/01/09/llava/#training">Training</a></h4>
<p>Two stages of training:</p>
<ol>
<li>Pre-training for Feature Alignment: LLaVA aligns visual and language features to ensure compatibility in this initial stage.</li>
<li>Fine-tune end-to-end: The second training stage focuses on fine-tuning the entire model. At this stage the vision encoder's weights remain fixed</li>
</ol>
<h3 id="llava-15"><a class="toclink" href="../../2025/01/09/llava/#llava-15">LLaVA-1.5</a></h3>
<p>In LLaVA-1.5 there are two significant changes:
1. MLP vision-language connector
2. Trained for academic task-oriented data.</p>
<p>The linear projection layer is replaced with a 2 layer MLP.</p>
<h3 id="llava-16-llava-next"><a class="toclink" href="../../2025/01/09/llava/#llava-16-llava-next">LLaVA 1.6 (LLaVA-NeXT)</a></h3>
<p>n addition to LLaVA 1.5, which uses the Vicuna-1.5 (7B and 13B) LLM backbone, LLaVA 1.6 considers more LLMs, including Mistral-7B and Nous-Hermes-2-Yi-34B. These LLMs possess nice properties, flexible commercial use terms, strong bilingual support, and a larger language model capacity. It allows LLaVA to support a broader spectrum of users and more scenarios in the community. The LLaVA recipe works well with various LLMs and scales up smoothly with the LLM up to 34B.</p>
<p>Here are the performance improvements LLaVA-NeXT has over LLaVA-1.5:</p>
<p>Increasing the input image resolution to 4x more pixels. This allows it to grasp more visual details. It supports three aspect ratios, up to 672x672, 336x1344, and 1344x336 resolution.
Better visual reasoning and zero-shot OCR capability with multimodal document and chart data.
Improved visual instruction tuning data mixture with a higher diversity of task instructions and optimizing for responses that solicit favorable user feedback.
Better visual conversation for more scenarios covering different applications. Better world knowledge and logical reasoning.
Efficient deployment and inference with SGLang.</p>
<p>Other variants of LLaVA:
1. LLaVA-Med
2. LLaVA-Interactive</p>
<h3 id="reference"><a class="toclink" href="../../2025/01/09/llava/#reference">Reference</a></h3>
<ol>
<li>A. Acharya, “LLAVA, LLAVA-1.5, and LLAVA-NeXT(1.6) explained,” Nov. 04, 2024. https://encord.com/blog/llava-large-language-vision-assistant/</li>
<li>Wikipedia contributors, “Llama (language model),” Wikipedia, Jan. 01, 2025. https://en.wikipedia.org/wiki/Llama_(language_model)</li>
</ol>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/39479720?s=400&u=17af60674de436a0ef97d3e528947194708b03bd&v=4" alt="Alton Lavin D'souza">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-08-26 00:00:00+00:00">August 26, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">LLMs</a>, 
              <a href="../tensorflow/" class="md-meta__link">Tensorflow</a>, 
              <a href="../pytorch/" class="md-meta__link">Pytorch</a>, 
              <a href="../computational-graphs/" class="md-meta__link">Computational Graphs</a>, 
              <a href="../partial-differentiation/" class="md-meta__link">Partial Differentiation</a></li>
        
        
          
          <li class="md-meta__item">
            
              4 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="computational-graphs"><a class="toclink" href="../../2024/08/26/computational-graphs/">Computational Graphs</a></h2>
<p>These are Directed Graphs that helps map out dependencies for mathematical computations. For Example let us consider the following set of equations:</p>
<ol>
<li>Y=(a-b)*(a+b)</li>
<li>Let d=(a-b) and e=(a+b)</li>
</ol>
<p>Our dependency graph will look as follows:</p>
<p><img alt="Graph Example" src="../../pics/Graph.png" /></p>
<p>The lower nodes are evaluated first then the higher nodes are evaluated.</p>
<p>Let us consider how this works when performing chain differentiation when it comes to neural networks. </p>
<p>To review chain differentiation consider the following equation:</p>
<ol>
<li>y = <span class="arithmatex">\(u^4\)</span></li>
<li>u = 3x + 2 </li>
</ol>
<p>Performing chain rule differentiation with respect to x we would get the follolwing:</p>
<p>We first perform partial differentiation of <code>u</code> with respect to <code>x</code></p>
<div class="arithmatex">\[\frac{\partial u}{\partial x} = 3 \]</div>
<p>Then perform partial differentiation of <code>y</code> with respect to <code>u</code></p>
<div class="arithmatex">\[\frac{\partial y}{\partial u} = 4u^3\]</div>
<p>Can be re-written as:</p>
<div class="arithmatex">\[ \frac{\partial y}{3\partial x} = 4u^3\]</div>
<div class="arithmatex">\[ \frac{\partial y}{\partial x} = 12 u^3\]</div>
<p>if x = 3.0 </p>
<p>u = 11</p>
<p><span class="arithmatex">\(\frac{\partial y}{\partial x} = 15972\)</span> </p>
<p>Representing the above steps in a computational graph we get the following: </p>
<p><img alt="Chained Computational Graph" src="../../pics/Chained%20Equation.png" /></p>
<p>How do we implement this? Luckily this has already been implemented for us in Tensorflow and Pytorch.</p>
<p>There are 2 implementations of Computational Graphs:</p>
<ol>
<li>Static Computational Graphs - Graphs are constructed once befor the execution of the model.</li>
<li>Dynamic Computational Graphs - Graphs are constructed on the fly.</li>
</ol>
<h3 id="tensorflow-computation-graph-implementation"><a class="toclink" href="../../2024/08/26/computational-graphs/#tensorflow-computation-graph-implementation">Tensorflow Computation Graph implementation.</a></h3>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="mf">2024</span><span class="o">-</span><span class="mf">08</span><span class="o">-</span><span class="mf">27</span><span class="w"> </span><span class="mf">18</span><span class="p">:</span><span class="mf">45</span><span class="p">:</span><span class="mf">09.326809</span><span class="p">:</span><span class="w"> </span><span class="n">E</span><span class="w"> </span><span class="n">external</span><span class="o">/</span><span class="n">local_xla</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">cuda_fft</span><span class="mf">.</span><span class="n">cc</span><span class="p">:</span><span class="mf">485</span><span class="err">]</span><span class="w"> </span><span class="n">Unable</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">register</span><span class="w"> </span><span class="n">cuFFT</span><span class="w"> </span><span class="n">factory</span><span class="p">:</span><span class="w"> </span><span class="n">Attempting</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">register</span><span class="w"> </span><span class="n">factory</span><span class="w"> </span><span class="kr">for</span><span class="w"> </span><span class="n">plugin</span><span class="w"> </span><span class="n">cuFFT</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="kr">on</span><span class="n">e</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">already</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">registered</span>
<span class="mf">2024</span><span class="o">-</span><span class="mf">08</span><span class="o">-</span><span class="mf">27</span><span class="w"> </span><span class="mf">18</span><span class="p">:</span><span class="mf">45</span><span class="p">:</span><span class="mf">09.357051</span><span class="p">:</span><span class="w"> </span><span class="n">E</span><span class="w"> </span><span class="n">external</span><span class="o">/</span><span class="n">local_xla</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">cuda_dnn</span><span class="mf">.</span><span class="n">cc</span><span class="p">:</span><span class="mf">8454</span><span class="err">]</span><span class="w"> </span><span class="n">Unable</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">register</span><span class="w"> </span><span class="n">cuDNN</span><span class="w"> </span><span class="n">factory</span><span class="p">:</span><span class="w"> </span><span class="n">Attempting</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">register</span><span class="w"> </span><span class="n">factory</span><span class="w"> </span><span class="kr">for</span><span class="w"> </span><span class="n">plugin</span><span class="w"> </span><span class="n">cuDNN</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="kr">on</span><span class="n">e</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">already</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">registered</span>
<span class="mf">2024</span><span class="o">-</span><span class="mf">08</span><span class="o">-</span><span class="mf">27</span><span class="w"> </span><span class="mf">18</span><span class="p">:</span><span class="mf">45</span><span class="p">:</span><span class="mf">09.365983</span><span class="p">:</span><span class="w"> </span><span class="n">E</span><span class="w"> </span><span class="n">external</span><span class="o">/</span><span class="n">local_xla</span><span class="o">/</span><span class="n">xla</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">cuda</span><span class="o">/</span><span class="n">cuda_blas</span><span class="mf">.</span><span class="n">cc</span><span class="p">:</span><span class="mf">1452</span><span class="err">]</span><span class="w"> </span><span class="n">Unable</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">register</span><span class="w"> </span><span class="n">cuBLAS</span><span class="w"> </span><span class="n">factory</span><span class="p">:</span><span class="w"> </span><span class="n">Attempting</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">register</span><span class="w"> </span><span class="n">factory</span><span class="w"> </span><span class="kr">for</span><span class="w"> </span><span class="n">plugin</span><span class="w"> </span><span class="n">cuBLAS</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="kr">on</span><span class="n">e</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">already</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">registered</span>
<span class="mf">2024</span><span class="o">-</span><span class="mf">08</span><span class="o">-</span><span class="mf">27</span><span class="w"> </span><span class="mf">18</span><span class="p">:</span><span class="mf">45</span><span class="p">:</span><span class="mf">09.395484</span><span class="p">:</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">tensorflow</span><span class="o">/</span><span class="n">core</span><span class="o">/</span><span class="n">platform</span><span class="o">/</span><span class="n">cpu_feature_guard</span><span class="mf">.</span><span class="n">cc</span><span class="p">:</span><span class="mf">210</span><span class="err">]</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="n">TensorFlow</span><span class="w"> </span><span class="n">binary</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">optimized</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">available</span><span class="w"> </span><span class="n">CPU</span><span class="w"> </span><span class="n">instructions</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">performance</span><span class="o">-</span><span class="n">critical</span><span class="w"> </span><span class="n">operations</span><span class="mf">.</span>
<span class="kr">To</span><span class="w"> </span><span class="n">enable</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">instructions</span><span class="p">:</span><span class="w"> </span><span class="n">AVX2</span><span class="w"> </span><span class="n">FMA</span><span class="p">,</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">operations</span><span class="p">,</span><span class="w"> </span><span class="n">rebuild</span><span class="w"> </span><span class="n">TensorFlow</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">appropriate</span><span class="w"> </span><span class="n">compiler</span><span class="w"> </span><span class="n">flags</span><span class="mf">.</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">tape</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">u</span> <span class="o">**</span> <span class="mi">4</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">WARNING</span><span class="o">:</span><span class="w"> </span><span class="n">All</span><span class="w"> </span><span class="n">log</span><span class="w"> </span><span class="n">messages</span><span class="w"> </span><span class="n">before</span><span class="w"> </span><span class="n">absl</span><span class="o">::</span><span class="n">InitializeLog</span><span class="o">()</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">written</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">STDERR</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784312.756873</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784312.767002</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784312.767097</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784312.777530</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784312.777763</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784312.777895</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784313.020475</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784313.020614</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">27</span><span class="w"> </span><span class="mi">18</span><span class="o">:</span><span class="mi">45</span><span class="o">:</span><span class="mf">13.020636</span><span class="o">:</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">tensorflow</span><span class="sr">/core/common_runtime/gpu/g</span><span class="n">pu_device</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">2112</span><span class="o">]</span><span class="w"> </span><span class="n">Could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">identify</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">platform</span><span class="w"> </span><span class="n">GPU</span><span class="w"> </span><span class="n">id</span><span class="w"> </span><span class="mi">0</span><span class="o">,</span><span class="w"> </span><span class="n">defaulting</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="mi">0</span><span class="o">.</span><span class="w">  </span><span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="n">I0000</span><span class="w"> </span><span class="mi">00</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">1724784313.020750</span><span class="w">    </span><span class="mi">1081</span><span class="w"> </span><span class="n">cuda_executor</span><span class="o">.</span><span class="na">cc</span><span class="o">:</span><span class="mi">1001</span><span class="o">]</span><span class="w"> </span><span class="n">could</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">open</span><span class="w"> </span><span class="n">file</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">node</span><span class="o">:</span><span class="w"> </span><span class="sr">/sys/bus/pci/devices/0000:01:00.0/</span><span class="n">numa_node</span>
<span class="n">Your</span><span class="w"> </span><span class="n">kernel</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">been</span><span class="w"> </span><span class="n">built</span><span class="w"> </span><span class="n">without</span><span class="w"> </span><span class="n">NUMA</span><span class="w"> </span><span class="n">support</span><span class="o">.</span>
<span class="mi">2024</span><span class="o">-</span><span class="mi">08</span><span class="o">-</span><span class="mi">27</span><span class="w"> </span><span class="mi">18</span><span class="o">:</span><span class="mi">45</span><span class="o">:</span><span class="mf">13.020821</span><span class="o">:</span><span class="w"> </span><span class="n">I</span><span class="w"> </span><span class="n">tensorflow</span><span class="sr">/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/</span><span class="n">device</span><span class="o">:</span><span class="n">GPU</span><span class="o">:</span><span class="mi">0</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="mi">1767</span><span class="w"> </span><span class="n">MB</span><span class="w"> </span><span class="n">memory</span><span class="o">:</span><span class="w">  </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">device</span><span class="o">:</span><span class="w"> </span><span class="mi">0</span><span class="o">,</span><span class="w"> </span><span class="n">name</span><span class="o">:</span><span class="w"> </span><span class="n">NVIDIA</span><span class="w"> </span><span class="n">GeForce</span><span class="w"> </span><span class="n">RTX</span><span class="w"> </span><span class="mi">3050</span><span class="w"> </span><span class="n">Laptop</span><span class="w"> </span><span class="n">GPU</span><span class="o">,</span><span class="w"> </span><span class="n">pci</span><span class="w"> </span><span class="n">bus</span><span class="w"> </span><span class="n">id</span><span class="o">:</span><span class="w"> </span><span class="mi">0000</span><span class="o">:</span><span class="mi">01</span><span class="o">:</span><span class="mf">00.0</span><span class="o">,</span><span class="w"> </span><span class="n">compute</span><span class="w"> </span><span class="n">capability</span><span class="o">:</span><span class="w"> </span><span class="mf">8.6</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">g</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">g</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="p">&lt;</span><span class="nx">tf</span><span class="p">.</span><span class="nx">Tensor</span><span class="p">:</span><span class="w"> </span><span class="nx">shape</span><span class="p">=(),</span><span class="w"> </span><span class="nx">dtype</span><span class="p">=</span><span class="nx">float32</span><span class="p">,</span><span class="w"> </span><span class="nx">numpy</span><span class="p">=</span><span class="m m-Double">15972.0</span><span class="p">&gt;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<h3 id="pytorch-computation-graph-implementation"><a class="toclink" href="../../2024/08/26/computational-graphs/#pytorch-computation-graph-implementation">Pytorch Computation Graph Implementation.</a></h3>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span><span class="mi">2</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">u</span><span class="o">**</span><span class="mi">4</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>tensor(15972.)
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>
</code></pre></div>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/39479720?s=400&u=17af60674de436a0ef97d3e528947194708b03bd&v=4" alt="Alton Lavin D'souza">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-05-31 00:00:00+00:00">May 31, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">LLMs</a>, 
              <a href="../nlp/" class="md-meta__link">NLP</a>, 
              <a href="../vectordb/" class="md-meta__link">VectorDB</a></li>
        
        
          
          <li class="md-meta__item">
            
              2 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="why-go-for-rag"><a class="toclink" href="../../2024/05/31/why-go-for-rag/">Why go for RAG?</a></h2>
<h3 id="overview"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#overview">Overview</a></h3>
<p>In this project we choose a foundational model i.e. GPT or BERT and create an API that makes it easy to interact with the LLM.</p>
<h3 id="foundational-model"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#foundational-model">Foundational model</a></h3>
<p>We want a foundational model that can interact in the medical context. Some of the models considered here are :</p>
<ul>
<li><a href="https://huggingface.co/ruslanmv/Medical-Llama3-8B">Medical Llama-8b</a> - Optimized to address health related inquiries and trained on comprehensive medical chatbot dataset (Apache License 2.0) foundational model used here Meta-Llama-3-8b</li>
<li><a href="https://huggingface.co/aaditya/Llama3-OpenBioLLM-8B">Llama3-OpenBioLLM-8B</a> - fine tuned on corpus of high quality of biomedical data, 8 billion parameters. Incorporated the DPO data set</li>
</ul>
<h3 id="approaches"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#approaches">Approaches</a></h3>
<p>To create a chat bot we have 2 approaches:</p>
<ul>
<li>Fine tuning existing foundational models on medical data set</li>
<li>Create a Retrieval augmented generation framework which is used for retrieving facts from an external knowledge</li>
</ul>
<p><img alt="Comparisons" src="../../pics/Screenshot%202024-05-31%20122720.png" /></p>
<h4 id="fine-tuning-existing-foundation-models-on-medical-data-set"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#fine-tuning-existing-foundation-models-on-medical-data-set">Fine tuning existing foundation models on medical data set</a></h4>
<ul>
<li>Incorporates the additional knowledge into the model itself</li>
<li>Offers a precise, succinct output that is attuned to brevity.</li>
<li>High initial cost</li>
<li>Minimum input size </li>
</ul>
<h4 id="retrieval-augmented-generation"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#retrieval-augmented-generation">Retrieval Augmented Generation</a></h4>
<ul>
<li>Augments the prompt with external data</li>
<li>Provides an additional context during question answering.</li>
<li>Possible collision among similar snippets during the retrieval process</li>
<li>RAG has larger input size due to inclusion of context information ,output information tends to be more verbose and harder to steer.</li>
</ul>
<h4 id="experiment-conclusion"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#experiment-conclusion">Experiment Conclusion</a></h4>
<p>GPT learned 47% of new knowledge with fine-tuning with RAG this number goes upto 72% and 74%.</p>
<h3 id="preferred-approach"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#preferred-approach">Preferred approach</a></h3>
<h4 id="what-we-want"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#what-we-want">What we want?</a></h4>
<ul>
<li>Fast Deployment option</li>
</ul>
<h4 id="choice-of-approach"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#choice-of-approach">Choice of Approach</a></h4>
<p>RAG allows to create embeddings easily and allows for a fast deployment option.</p>
<h3 id="architecture"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#architecture">Architecture</a></h3>
<p><img alt="Architecture" src="../../pics/AI_copilot_service.drawio.png" /></p>
<h3 id="references"><a class="toclink" href="../../2024/05/31/why-go-for-rag/#references">References</a></h3>
<ul>
<li>https://arxiv.org/pdf/2401.08406</li>
</ul>
    
  </div>
</article>
      
        <article class="md-post md-post--excerpt">
  <header class="md-post__header">
    
      <nav class="md-post__authors md-typeset">
        
          <span class="md-author">
            <img src="https://avatars.githubusercontent.com/u/39479720?s=400&u=17af60674de436a0ef97d3e528947194708b03bd&v=4" alt="Alton Lavin D'souza">
          </span>
        
      </nav>
    
    <div class="md-post__meta md-meta">
      <ul class="md-meta__list">
        <li class="md-meta__item">
          <time datetime="2024-05-21 00:00:00+00:00">May 21, 2024</time></li>
        
          <li class="md-meta__item">
            in
            
              <a href="./" class="md-meta__link">LLMs</a>, 
              <a href="../nlp/" class="md-meta__link">NLP</a></li>
        
        
          
          <li class="md-meta__item">
            
              1 min read
            
          </li>
        
      </ul>
      
    </div>
  </header>
  <div class="md-post__content md-typeset">
    <h2 id="langchain"><a class="toclink" href="../../2024/05/21/langchain/">LangChain</a></h2>
<h3 id="overview"><a class="toclink" href="../../2024/05/21/langchain/#overview">Overview</a></h3>
<p>Consists of 3 components:</p>
<ul>
<li>Components:</li>
<li>LLM Wrappers</li>
<li>Prompt Templates</li>
<li>Indexes for information Retrieval</li>
<li>Chains: Assemble Components to solve a specific task</li>
<li>Agents: allows LLMs To interact with it's environment</li>
</ul>
<h3 id="installation"><a class="toclink" href="../../2024/05/21/langchain/#installation">Installation</a></h3>
<ul>
<li>Use Pycharm as your preferred IDE since it makes things easier and user friendly</li>
<li>Create a new project in Pycharm which looks as follows:</li>
</ul>
<p><img alt="Create Project Window" src="../../pics/Screenshot%202024-05-21%20141210.png" /></p>
<h3 id="references"><a class="toclink" href="../../2024/05/21/langchain/#references">References</a></h3>
<ol>
<li><a href="https://www.youtube.com/watch?v=lG7Uxts9SXs&amp;t=2018s">Youtube</a></li>
</ol>
    
  </div>
</article>
      
      
        
          



<nav class="md-pagination">
  
</nav>
        
      
    </div>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.indexes"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>